<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Guided Attention with Language Alignment for Open Vocabulary Gaussian Splatting.">
  <meta name="keywords" content="3D Scene Understanding, 3DGS, Open-Vocabulary">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GALA: Guided Attention with Language Alignment for Open Vocabulary Gaussian Splatting</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/favicon.svg?v=2">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">GALA: Guided Attention with Language Alignment for Open Vocabulary Gaussian Splatting</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://elenaalegret.github.io/">Elena Alegret</a><sup>1,2,6,*</sup>,</span>
            <span class="author-block">
              <a href="https://li-kunyi.github.io/">Kunyi Li</a><sup>1,4,*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=OxZ9S6oAAAAJ&hl=en">Sen Wang</a><sup>1,4</sup>,
            </span>
            <span class="author-block">
              <a href="https://siyun-liang.github.io/">Siyun Liang</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=YuWTPaIAAAAJ&hl=en">Stefano Gasperini</a><sup>1,4,7</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.professoren.tum.de/en/navab-nassir">Nassir Navab</a><sup>1,4</sup>
            </span>
            <span class="author-block">
              <a href="https://federicotombari.github.io/">Federico Tombari</a><sup>1,3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup> Equal Contribution,</span>
            <span class="author-block"><sup>1</sup>Technical University of Munich,</span>
            <span class="author-block"><sup>2</sup>Universitat Politecnica de Catalunya,</span>
            <span class="author-block"><sup>3</sup>Google,</span>
            <span class="author-block"><sup>4</sup>Munich Center for Machine Learning,</span>
            <span class="author-block"><sup>5</sup>University of Tubingen,</span>
            <span class="author-block"><sup>6</sup>ETH Zurich,</span>  
            <span class="author-block"><sup>7</sup>Visualais</span> 
          </div>

          <h1 class="cvpr-title">3DV 2025</h1>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2508.14278"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2508.14278"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/elenaalegret/GALA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- < span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>  -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce GALA, a novel framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting (3DGS). 
            GALA distills a scenespecific 3D instance feature field via self-supervised contrastive learning. To extend to generalized 
            language feature fields, we introduce the core contribution of GALA, a crossattention module with two learnable codebooks 
            that encode view-independent semantic embeddings. This design not only ensures intra-instance feature similarity but also
            supports seamless 2D and 3D open-vocabulary queries. It reduces memory consumption by avoiding per-Gaussian high-dimensional 
            feature learning. Extensive experiments on real-world datasets demonstrate GALAâ€™s remarkable open-vocabulary performance on both 2D and 3D.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <!-- Paper image. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">GALA</h2>
        <div class="publication-image">
          <img src="./static/images/architecture.jpg"
              alt="GALA teaser"
              style="width: 100%; height: auto;">
        </div>
      </div>
    </div>
    <!--/ Paper image. -->
  </div>
</section> 


    <!-- 2D Open-Vocabulary Query Image -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">2D Open-Vocabulary Query</h2>
        <div class="publication-image">
          <img src="./static/images/2DOpen-VocabularyQuery.jpg"
              alt="GALA teaser"
              style="width: 80%; height: auto;">
        </div>
      </div>
    </div>
    <!--/ 2D Open-Vocabulary Query Image -->
  </div>
</section> 


    <!-- 3D Open-Vocabulary Segmentation Image -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">3D Open-Vocabulary Segmentation</h2>
        <div class="publication-image">
          <img src="./static/images/3D Open-Vocabulary Segmentation.jpg"
              alt="GALA teaser"
              style="width: 80%; height: auto;">
        </div>
      </div>
    </div>
    <!--/ 3D Open-Vocabulary Segmentation Image -->
  </div>
</section> 

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  <!-- </div>
</section> -->


 <!-- 
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      --><!-- Visual Effects. --><!--/
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      --><!--/ Visual Effects. -->

      <!-- Matting. --><!--/
      <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    --><!--/ Matting. -->

    <!-- Animation. --><!--/
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2>

        --><!-- Interpolating. --><!--/
        <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>
        --><!--/ Interpolating. --><!--/

      </div>
    </div>
    --><!--/ Animation. --><!--/

  </div>
</section>
-->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{alegret2025gala, 
      author = {Elena Alegret* and Kunyi Li* and Sen Wang and Siyun Liang and Michael Niemeyer and Stefano Gasperini and Nassir Navab and Federico Tombari}, 
      title = {GALA: Guided Attention with Language Alignment for Open Vocabulary Gaussian Splatting}, 
      booktitle = {International Conference on 3D Vision (3DV)}, 
      year = {2026},
    }</code></pre>
  </div>
</section>

